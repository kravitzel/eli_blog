{
  "hash": "0fba6ba75ce6524b44586bdccd503244",
  "result": {
    "markdown": "---\ntitle: \"Data.table's (Not Quite) Left Joins\"\nauthor: \"Eli Kravitz\"\ndate: \"2023-08-19\"\ncategories: [R, data.table]\nimage: \"wood_join.jpg\"\nformat: \n  html:\n    df-print: default\n---\n\n\n## Introduction\n\nLike many other R users, I've integrated `data.table` ([CRAN](https://cran.r-project.org/web/packages/data.table/vignettes/datatable-intro.html \"data.table CRAN vignette\"), [Github](https://github.com/Rdatatable/data.table \"data.table Github page\")) into my R workflow. `data.table` is [lightning-fast](https://h2oai.github.io/db-benchmark/ \"database and dataframe benchmarks\"), with common table operations running faster than most R, Python, or standalone alternative. Many people prefer `data.table`'s [concise syntax](https://atrebas.github.io/post/2020-06-17-datatable-introduction/ \"A gentle introduction to data.table\") to `tidyverse` / `dplyr` [style of pipes and verbs](https://dplyr.tidyverse.org/ \"dplyr homepage\"). (I am *not* one of those people. I mostly use the `tidytable`[package](https://github.com/markfairbanks/tidytable \"tidytable homepage\") which implements `tidyverse`syntax for `data.tables`).\n\nFor as much as I appreciate `data.table`, it often lacks proper documentation. In particular, the package has no documentation on joins. That leaves the users to learn `data.table` joins by trial-and-error or through [second hand resources](https://gist.github.com/nacnudus/ef3b22b79164bbf9c0ebafbf558f22a0 \"Github gist for data.table joins\") and [Stack Overflow](https://stackoverflow.com/a/34600831/2838936 \"StackOverflow link #2\") [answers](https://stackoverflow.com/questions/12773822/why-does-xy-join-of-data-tables-not-allow-a-full-outer-join-or-a-left-join \"StackOverflow link #2\"). This fragmented documentation can mask some eccentricities of `data.table`.\n\n## The Left Join That Wasn't\n\nAs of mid 2023 , the first Google search result for \"data.table left join\" is this [Stack Overflow answer](https://stackoverflow.com/a/34600831/2838936 \"Stack Overflow left-join\") and [this Stack Overflow answer](https://stackoverflow.com/a/54313203/2838936 \"Stack Overflow answer #2\"). Unfortunately, this code **does not produce a left join**, at least in the traditional SQL sense. Props to Stack Overflow user [Helen](https://stackoverflow.com/users/2820289/helen \"Stack Overflow user page for Helen\"){style=\"caret-color: white; font-size: 14pt;\"} for pointing [this issue](https://stackoverflow.com/a/65856995/2838936){style=\"caret-color: white; font-size: 14pt;\"}. To be fair, this misconception is widespread, so it must be coming from many places.\n\n### The Problem\n\nThe common advice you'll get for joining `data.tables` is to use `:=` operator to update the left table *by reference* (\"in place\") with the new column(s) from the right table. Pseudo-code would look something like this:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nLEFT_TABLE[RIGHT_TABLE, on=\"id\", col_from_left := i.col_from_right]\n```\n:::\n\n\nThe problem is `data.table` does not return multiple matches when you modify by reference. It returns *only* the last match, instead of returning all matches. See below:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(data.table)\nA = data.table(id = c(\"x\", \"y\", \"z\"), \n               a_var = c(100, 200, 300))\nB = data.table(id = rep(c(\"w\", \"x\", \"y\", \"z\"), each = 2), \n               b_var = seq(1, 8, by = 1))\n\n# \"Left join\". New values added by reference \nA[B, on = \"id\", new_var := i.b_var]\n\nprint(A)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   id a_var new_var\n1:  x   100       4\n2:  y   200       6\n3:  z   300       8\n```\n:::\n:::\n\n\nThis returns the wrong number of rows. We should get 6 rows total: each row of A should match two rows in B.\n\nCompare this with other implementations of left join, and you'll see the expected behavior.\n\n::: panel-tabset\n## dplyr\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndplyr::left_join(A, B, by = \"id\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   id a_var new_var b_var\n1:  x   100       4     3\n2:  x   100       4     4\n3:  y   200       6     5\n4:  y   200       6     6\n5:  z   300       8     7\n6:  z   300       8     8\n```\n:::\n:::\n\n\n## Base R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmerge.data.frame(A, B, by = \"id\", all.x =TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  id a_var new_var b_var\n1  x   100       4     3\n2  x   100       4     4\n3  y   200       6     5\n4  y   200       6     6\n5  z   300       8     7\n6  z   300       8     8\n```\n:::\n:::\n\n\n## SQL\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsqldf::sqldf(\n  \"SELECT \n    A.id, A.a_var, B.b_var\n  FROM A\n  LEFT JOIN B \n    ON A.id=B.id\n\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\ntcltk DLL is linked to '/opt/X11/lib/libX11.6.dylib'\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n  id a_var b_var\n1  x   100     3\n2  x   100     4\n3  y   200     5\n4  y   200     6\n5  z   300     7\n6  z   300     8\n```\n:::\n:::\n\n:::\n\n## Avoiding the issue\n\nUpdating by value avoids this issue. Of course, you'd need to assign this to a variable.\n\nYou can use the `merge` syntax:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmerge.data.table(A, B, by = \"id\", all.x = TRUE)\n```\n:::\n\n\nOr, you can use the `X[Y]` shorthand without assigning new variables by reference with `:=`. Confusingly, when using the `X[Y]` shorthand syntax, you have to reverse the direction of the *join*.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nB[A, on = \"id\"] # Instead of A[B]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   id b_var a_var new_var\n1:  x     3   100       4\n2:  x     4   100       4\n3:  y     5   200       6\n4:  y     6   200       6\n5:  z     7   300       8\n6:  z     8   300       8\n```\n:::\n:::\n\n\n## Should I Ever Use the Other Join?\n\nYes! These \"update by reference joins\" are *really* efficient if you know the single match behavior and account for it.\n\nNormally, R copies the new dataframe in memory after a join. For large datasets, this can be memory intensive and time consuming. You can track this behavior with Hadley Wickham's `lobstr` [package](https://lobstr.r-lib.org/ \"Lobstr package website\").\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# See where data.tables are stored in memory\nlobstr::obj_addrs(list(A, B))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"0x7f840dc57a00\" \"0x7f8409d3b200\"\n```\n:::\n\n```{.r .cell-code}\njoined_df = merge.data.table(A, B, by = \"id\")\nlobstr::obj_addr(joined_df) # New location in memory\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"0x7f840e910600\"\n```\n:::\n:::\n\n\nWhen you update-join, the dataframes keep their place in memory. New columns are appended without modifying the objects location in memory.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlobstr::obj_addr(A)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"0x7f840dc57a00\"\n```\n:::\n\n```{.r .cell-code}\nA[B, on = \"id\", foo := 123 * i.b_var]\nlobstr::obj_addr(A) # same location in memory\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"0x7f840dc57a00\"\n```\n:::\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}